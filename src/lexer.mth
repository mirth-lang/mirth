module mirth.lexer

import std.prelude
import std.byte
import std.path
import std.str
import std.maybe
import std.list
import std.ctypes
import std.world
import std.file
import std.input

import mirth.location
import mirth.name
import mirth.label
import mirth.token
import mirth.mirth
import mirth.module


#########
# LEXER #
#########

struct +Lexer {
    lexer-module:Module
    lexer-row:Row
    lexer-col:Col
    lexer-doc:Maybe(Str)
    lexer-stack:List(Token)
    lexer-first-token:Token
    lexer-last-token:Token
    +input: +Input
    --
    def stack-push! [ Token +Lexer -- +Lexer ] { lexer-stack:cons }
    def stack-pop!  [ +Lexer -- Maybe(Token) +Lexer ] { lexer-stack:uncons }
    def stack-drop  [ +Lexer -- +Lexer ] { lexer-stack:tail }
    def stack-peek  [ +Lexer -- Maybe(Token) +Lexer ] { lexer-stack head }

    def Start! [ Module +Input -- +Lexer ] {
        >+input
        >lexer-module
        1 Row >lexer-row
        1 Col >lexer-col
        None >lexer-doc
        L0 >lexer-stack
        Token.alloc-none! dup
        >lexer-first-token
        >lexer-last-token
        +Lexer
    }

    def stop! [ +Mirth +Lexer -- Module +Mirth +Input ] {
        TokenValue.None emit!
        /+Lexer
        lexer-stack> uncons drop for("Mismatched token." emit-fatal-error!)
        lexer-row> lexer-col> lexer-last-token> drop3
        lexer-module> Token.alloc-none! over ~end !
        lexer-first-token> succ over ~start !
        lexer-doc> drop
        +input>
    }

    def lexer-location [ +Lexer -- +Lexer Location ] {
        lexer-module >module
        lexer-row >row
        lexer-col >col
        Location
    }
    def warning! [ Str +Mirth +Lexer -- +Mirth +Lexer ] { dip:lexer-location rdip:emit-warning-at! }
    def error! [ Str +Mirth +Lexer -- +Mirth +Lexer ] { dip:lexer-location rdip:emit-error-at! }
    def fatal-error! [ *a Str +Mirth +Lexer -- *b ] { dip:lexer-location rswap emit-fatal-error-at! }

    def done? [ +Lexer -- +Lexer Bool ] { +input:done? }
    def peek  [ +Lexer -- +Lexer Byte ] { +input:peek }
    def move! [ +Lexer -- +Lexer ] { +input:move! lexer-col:1+ }
    def newline! [ +Lexer -- +Lexer ] { 0 Col lexer-col! lexer-row:1+ }

    ||| Create a token at the current location with the given payload.
    def make! [ TokenValue +Lexer -- Token +Lexer ] {
        Token.alloc!
        tuck ~value !
        lexer-module over ~module !
        lexer-row over ~row !
        lexer-col over ~col !
        lexer-doc over ~doc !
        None lexer-doc!
        dup lexer-last-token!
    }

    ||| Create a token at the current location, and then build the payload (while consuming characters).
    def make!(f) [ ( *a +Lexer -- *b TokenValue +Lexer ) *a +Lexer -- *b Token +Lexer ] {
        TokenValue.None make!
        dip:f
        tuck ~value !
    }

    ||| Emit a token at the current location with the given payload. Same as make! but drops the token.
    def emit! [ TokenValue +Lexer -- +Lexer ] { make! drop }

    ||| Create a token at the current location, then build the payload. Same as make!(f) but drops the token.
    def emit!(f) { make!(f) drop }

    ||| Analyze the next byte (and next token).
    def next! [ +Mirth +Lexer -- +Mirth +Lexer ] {
        peek match {
            { BLF      -> newline! move! }
            { BSPACE   -> move! }
            { BHT      -> move! }
            { BVT      -> move! }
            { BCR      -> move! }
            { BHASH    -> skip-comment! }
            { BCOMMA   -> close-colons! TokenValue.Comma emit! move! }
            { BRPAREN  -> close-colons! emit-rparen!  move! }
            { BRSQUARE -> close-colons! emit-rsquare! move! }
            { BRCURLY  -> close-colons! emit-rcurly!  move! }
            { BCOLON   -> prepare-for-args! emit-lcolon!  move! }
            { BLPAREN  -> prepare-for-args! emit-lparen!  move! }
            { BLSQUARE -> prepare-for-atom! emit-lsquare! move! }
            { BLCURLY  -> prepare-for-atom! emit-lcurly!  move! }
            { BQUOTE   -> prepare-for-atom! emit-string!  move! }
            { _ ->
                is-name-byte if(
                    prepare-for-atom! emit-name!,
                    "Unrecognized byte." fatal-error!
                )
            }
        }
    }

    def close-colons! [ +Lexer -- +Lexer ] {
        while-some(
            stack-peek filter(lcolon-open?),
            stack-drop
            dup TokenValue.RColon make!
            TokenValue.LColon swap ~value !
        )
    }

    def prepare-for-atom! [ +Lexer -- +Lexer ] {
        lexer-last-token lcolon-open? else(close-colons!)
    }
    def prepare-for-args! [ +Lexer -- +Lexer ] {
        lexer-last-token can-take-args? else(close-colons!)
    }

    def emit-lcolon!  [ +Lexer -- +Lexer ] { TokenValue.LColonOpen  make! stack-push! }
    def emit-lparen!  [ +Lexer -- +Lexer ] { TokenValue.LParenOpen  make! stack-push! }
    def emit-lcurly!  [ +Lexer -- +Lexer ] { TokenValue.LCurlyOpen  make! stack-push! }
    def emit-lsquare! [ +Lexer -- +Lexer ] { TokenValue.LSquareOpen make! stack-push! }

    def emit-rparen! [ +Mirth +Lexer -- +Mirth +Lexer ] {
        stack-pop! filter(value lparen-open?)
        unwrap("Mismatched right parenthesis." fatal-error!)
        dup TokenValue.RParen make!
        TokenValue.LParen swap ~value !
    }

    def emit-rcurly! [ +Mirth +Lexer -- +Mirth +Lexer ] {
        stack-pop! filter(value lcurly-open?)
        unwrap("Mismatched right curly brace." fatal-error!)
        dup TokenValue.RCurly make!
        TokenValue.LCurly swap ~value !
    }

    def emit-rsquare! [ +Mirth +Lexer -- +Mirth +Lexer ] {
        stack-pop! filter(value lsquare-open?)
        unwrap("Mismatched right square bracket." fatal-error!)
        dup TokenValue.RSquare make!
        TokenValue.LSquare swap ~value !
    }

    def emit-name! [ +Mirth +Lexer -- +Mirth +Lexer ] {
        rdip("" thaw)
        lexer-module
        lexer-row
        lexer-col

        peek while(dup is-name-byte,
            rdip(push-byte-unsafe!)
            move! peek
        )
        drop

        rdip:is-doc-start? if(
            drop3
            skip-doc!,

            Token.alloc!
            tuck ~col !
            tuck ~row !
            tuck ~module !

            >+lexer
            float-token?
            or?(int-token?)
            or?(dname-token?)
            or?(label-token?)
            else?(name-token)
            over ~value !
            +lexer>
            lexer-doc over ~doc !

            lexer-last-token!
            None lexer-doc!
        )
        rdip(freeze drop)
    }

    def emit-string! [+Mirth +Lexer -- +Mirth +Lexer] {
        rdip("" thaw)
        emit! (
            move!
            peek while(dup is-string-end not,
                push-string-byte!
                move! peek
            )
            Byte.BQUOTE == else(
                "String literal is missing end quote (\")."
                rdip':fatal-error!
            )

            rdip:freeze TokenValue.Str
        )
    }

    def push-string-byte! [ +Mirth +Str +Lexer Byte -- +Mirth +Str +Lexer ] {
        { B'\' -> move! peek push-string-escape-byte! }
        { _ -> rdip:push-byte-unsafe! }
    }

    def push-string-escape-byte! [ +Mirth +Str +Lexer Byte -- +Mirth +Str +Lexer ] {
        { BLF -> newline! }
        { B'n' -> Byte.BLF rdip(push-byte-ascii!) }
        { B'r' -> Byte.BCR rdip(push-byte-ascii!) }
        { B't' -> Byte.BHT rdip(push-byte-ascii!) }
        { B'\' -> Byte.B'\' rdip(push-byte-ascii!) }
        { BQUOTE -> Byte.BQUOTE rdip(push-byte-ascii!) }
        { _ ->
            rdip(push-byte-unsafe!)
            "Unknown character escape sequence." rdip':warning!
        }
    }

    def skip-comment! [ +Lexer -- +Lexer ] {
        while(comment-end? not, move!)
        peek Byte.BLF == then(newline! move!)
    }

    def skip-doc! [ +Lexer -- +Lexer ] {
        lexer-doc else?("") rdip:thaw
        while(comment-end? not, peek rdip:push-byte-ascii! move!)
        peek Byte.BLF == then(newline! peek rdip:push-byte-ascii! move!)
        rdip:freeze Some
        lexer-doc!
    }

    def comment-end? [ +Lexer -- Bool +Lexer ] {
        done? or(peek Byte.BLF ==)
    }

}

def run-lexer! [ Path +World +Mirth -- Module +World +Mirth ] {
    Module.new! dup source-path
    rdip:open-file! rswap +else(fatal-error!) +Input.start!
    +Lexer.Start!
    while(done? not, next!)
    stop! rswap rdip(end! close-file!)
}

def(+Str.name-token, +Str -- TokenValue +Str, dup! >Name TokenValue.Name)

def(+Str.first-byte, +Str -- Byte +Str, 0u >UOffset byte@)
def(+Str.second-byte, +Str -- Byte +Str, 1u >UOffset byte@)
def(+Str.third-byte, +Str -- Byte +Str, 2u >UOffset byte@)

def(+Str.first-two-bytes, +Str +Unsafe -- Str +Str +Unsafe, 2u >USize +Str.take-slice)
def(+Str.last-two-bytes, +Str +Unsafe -- Str +Str +Unsafe,
    rdip:num-bytes? >UOffset pred pred +Str.drop-slice)

def(+Str.drop-first-byte, +Str +Unsafe -- Str +Str +Unsafe, 1u >UOffset +Str.drop-slice)
def(+Str.drop-first-two-bytes, +Str +Unsafe -- Str +Str +Unsafe, 2u >UOffset +Str.drop-slice)
def(+Str.drop-last-byte, +Str +Unsafe -- Str +Str +Unsafe,
    rdip:num-bytes? pred +Str.take-slice)
def(+Str.drop-last-two-bytes, +Str +Unsafe -- Str +Str +Unsafe,
    rdip:num-bytes? pred pred +Str.take-slice)

def(+Str.label-token?, +Str -- Maybe(TokenValue) +Str,
    label-push-token?
    or?(label-push-r-token?)
    or?(label-pop-token?)
    or?(label-pop-r-token?)
    or?(label-get-token?)
    or?(label-set-token?))

def(+Str.label-pop-token?, +Str -- Maybe(TokenValue) +Str,
    first-byte is-lower and(last-byte Byte.B'>' ==) if(
        unsafe(+Str.drop-last-byte) >Name Label.new! TokenValue.LabelPop Some,
        None
    ))

def(+Str.label-pop-r-token?, +Str -- Maybe(TokenValue) +Str,
    first-byte Byte.B'+' == and(second-byte is-lower and(last-byte Byte.B'>' ==)) if(
        unsafe(+Str.drop-last-byte) >Name Label.new! TokenValue.LabelPopR Some,
        None
    ))

def(+Str.label-push-token?, +Str -- Maybe(TokenValue) +Str,
    first-byte Byte.B'>' == and(second-byte is-lower) if(
        unsafe(+Str.drop-first-byte) >Name Label.new! TokenValue.LabelPush Some,
        None
    ))

def(+Str.label-push-r-token?, +Str -- Maybe(TokenValue) +Str,
    unsafe(+Str.first-two-bytes) ">+" == and(third-byte is-lower) if(
        unsafe(+Str.drop-first-byte) >Name Label.new! TokenValue.LabelPushR Some,
        None
    ))

def(+Str.label-get-token?, +Str -- Maybe(TokenValue) +Str,
    first-byte Byte.B'@' == and(second-byte is-lower or(second-byte Byte.B'+' == and(third-byte is-lower))) if(
        unsafe(+Str.drop-first-byte) >Name Label.new! TokenValue.LabelGet Some,
        None
    ))

def(+Str.label-set-token?, +Str -- Maybe(TokenValue) +Str,
    first-byte Byte.B'!' == and(second-byte is-lower or(second-byte Byte.B'+' == and(third-byte is-lower))) if(
        unsafe(+Str.drop-first-byte) >Name Label.new! TokenValue.LabelSet Some,
        None
    ))

def +Str.dname-token? [ +Str -- Maybe(TokenValue) +Str ] {
    Byte.BDOT +Str.split-byte
    uncons >Nest? match {
        { None -> drop None }
        { Some ->
            dip(dup Str.empty? if(drop None, >Name Some))
            map(>Name) DName TokenValue.DName Some
        }
    }
}

def(+Str.is-doc-start?, +Str -- Bool +Str,
    dup! "|||" ==)

def(+Str.is-arrow?, +Str -- Bool +Str,
    +Str.dup! "->" ==)

def(+Str.is-dashes?, +Str -- Bool +Str,
    dup! "--" ==)

def(+Str.is-float?, +Str -- Bool +Str,
    0u >USize
    0u >UOffset

    dup byte@ is-sign if(1+, id)

    while(dup byte@ is-digit, dip(1+) 1+)

    dup byte@ Byte.BDOT == if(
        dip(1+) 1+ while(dup byte@ is-digit, dip(1+) 1+)
        swap >Int 3 >= if(
            num-bytes? >UOffset ==,
            drop False
        ),
        drop2 False
    )
)

def +Str.float-token? [ +Mirth +Str Token -- +Mirth +Str Token Maybe(TokenValue) ] {
    is-float? >Maybe (
        dup! >F64? unwrap(
            "[lexer] bug: failed to parse float literal" rdip:emit-fatal-error!
        ) TokenValue.F64
    )
}

||| Process float sign and return initial state for rest float lexing.
||| returns: (sign multiplier) (str-buf index)
def(+Str.float-sign, +Str -- Byte UOffset +Str,
    0u >UOffset byte@ byte-sign-value-index-float)

def byte-sign-value-index-float [ Byte -- Byte UOffset ] {
    { B'-' -> Byte.B'-' 1u >UOffset }
    { B'+' -> Byte.B'+' 1u >UOffset }
    { _ -> drop Byte.B'+' 0u >UOffset }
}

def +Str.int-token? [ +Str -- Maybe(TokenValue) +Str ] {
    None
    or?(is-dec-int? >Maybe:dec-int?)
    or?(is-hex-int? >Maybe:hex-int?)
    or?(is-oct-int? >Maybe:oct-int?)
    map(TokenValue.Int)
}

def(+Str.is-dec-int?, +Str -- Bool +Str,
    0u >USize # number of digits
    0u >UOffset # current index
    dup byte@ is-sign if(1+, id)
    while(dup byte@ is-digit, dip(1+) 1+)
    swap 0> if(num-bytes? >UOffset ==, drop False))

def(+Str.is-hex-int?, +Str -- Bool +Str,
    0u >USize # number of digits
    0u >UOffset # current index
    dup byte@ is-sign if(
        1+,
        id
    )
    dup byte@ Byte.B'0' == if(
        1+
        dup byte@ Byte.B'x' == if(
            1+
            while(dup byte@ is-hexdigit, dip(1+) 1+)
            swap 0> if(
                num-bytes? >UOffset ==,
                drop False
            ),

            drop2 False
        ),

        drop2 False
    ))

def(+Str.is-oct-int?, +Str -- Bool +Str,
    0u >USize # number of digits
    0u >UOffset # current index
    dup byte@ is-sign if(
        1+,
        id
    )
    dup byte@ Byte.B'0' == if(
        1+
        dup byte@ Byte.B'o' == if(
            1+
            while(dup byte@ Byte.B'0' Byte.B'7' in-range, dip(1+) 1+)
            swap 0> if(
                num-bytes? >UOffset ==,
                drop False
            ),

            drop2 False
        ),

        drop2 False
    ))

||| process int sign and return initial state for rest of int lexing.
||| returns: (sign multiplier) (accumulated value == 0) (str-buf index)
def(+Str.int-sign, +Str -- Int Int UOffset +Str,
    0u >UOffset byte@ byte-sign-value-index)

def(byte-sign-value-index, Byte -- Int Int UOffset,
    B'-' -> -1 0 1u >UOffset,
    B'+' -> +1 0 1u >UOffset,
    _ -> drop +1 0 0u >UOffset)

def(+Str.dec-int?, +Str -- Int +Str,
    int-sign
    while(dup num-bytes? >UOffset <,
        sip(
            byte@ >Int
            dip(10 *) 48 - +
        )
        1+)
    drop *)

def(+Str.hex-int?, +Str -- Int +Str,
    int-sign 1+ 1+ # skip 0x prefix
    while(dup num-bytes? >UOffset <,
        sip(
            byte@
            dip(16 *) hexdigit-value +
        )
        1+)
    drop *)

def(+Str.oct-int?, +Str -- Int +Str,
    int-sign 1+ 1+ # skip 0o prefix
    while(dup num-bytes? >UOffset <,
        sip(
            byte@ >Int
            dip(8 *) 48 - +
        )
        1+)
    drop *)

def(hexdigit-value, Byte -- Int,
    dup is-digit if(
        >Int 48 -,
        to-upper >Int 55 -
    ))
