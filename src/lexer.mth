module mirth.lexer

import std.prelude
import std.byte
import std.path
import std.str
import std.maybe
import std.result
import std.list
import std.ctypes
import std.world
import std.file
import std.input
import std.unicode

import mirth.location
import mirth.name
import mirth.label
import mirth.token
import mirth.mirth
import mirth.module

#########
# LEXER #
#########

struct +Lexer {
    lexer-module:Module
    lexer-row:Row
    lexer-col:Col
    lexer-doc:Maybe(Str)
    lexer-stack:List(Token)
    lexer-first-token:Token
    lexer-last-token:Token
    content: Str
    index: Offset
    --
    def stack-push! [ +Lexer |- Token -- ] { lexer-stack:cons }
    def stack-pop!  [ +Lexer |- Maybe(Token) ] { lexer-stack:uncons }
    def stack-drop  [ +Lexer |- ] { lexer-stack:tail }
    def stack-peek  [ +Lexer |- Maybe(Token) ] { lexer-stack head }

    def Start! [ +Mirth |- content:Str Module -- +Lexer ] {
        >lexer-module
        0 >Offset >index
        1 Row >lexer-row
        1 Col >lexer-col
        None >lexer-doc
        L0 >lexer-stack
        Token.alloc-none! dup
        >lexer-first-token
        >lexer-last-token
        +Lexer
    }

    def stop! [ +Mirth |- +Lexer -- Module ] {
        TokenValue.None emit!
        /+Lexer
        lexer-stack> uncons drop for("Mismatched token." emit-fatal-error!)
        lexer-row> lexer-col> lexer-last-token> drop3
        lexer-module> Token.alloc-none! over ~end !
        lexer-first-token> succ over ~start !
        lexer-doc> drop
        content> drop index> drop
    }

    def lexer-location [ +Lexer |- Location ] {
        lexer-module >module
        lexer-row >row
        lexer-col >col
        Location
    }
    def warning! [ +Mirth +Lexer |- Str -- ] { dip:lexer-location rdip:emit-warning-at! }
    def error! [ +Mirth +Lexer |- Str -- ] { dip:lexer-location rdip:emit-error-at! }
    def fatal-error! [ *a Str +Mirth +Lexer -- *b ] { dip:lexer-location rswap emit-fatal-error-at! }

    def done? [ +Lexer -- +Lexer Bool ] { content num-bytes index <= }
    def peek  [ +Lexer -- +Lexer Byte ] { index content byte@ }
    def move! [ +Lexer -- +Lexer ] { index:1B+ lexer-col:1+ }
    def newline! [ +Lexer -- +Lexer ] { 0 Col lexer-col! lexer-row:1+ }

    ||| Create a token at the current location with the given payload.
    def make! [ +Lexer |- TokenValue -- Token ] {
        Token.alloc!
        tuck ~value !
        lexer-module over ~module !
        lexer-row over ~row !
        lexer-col over ~col !
        lexer-doc over ~doc !
        None lexer-doc!
        dup lexer-last-token!
    }

    ||| Create a token at the current location, and then build the payload (while consuming characters).
    def make!(f) [ +Lexer |- ( *a -- *b TokenValue ) *a -- *b Token ] {
        TokenValue.None make!
        dip:f
        tuck ~value !
    }

    ||| Emit a token at the current location with the given payload. Same as make! but drops the token.
    def emit! [ +Lexer |- TokenValue -- ] { make! drop }

    ||| Create a token at the current location, then build the payload. Same as make!(f) but drops the token.
    def emit!(f) { make!(f) drop }

    ||| Analyze the next byte (and next token).
    def next! [ +Mirth +Lexer |- ] {
        peek match {
            { BLF      -> newline! move! }
            { BSPACE   -> move! }
            { BHT      -> move! }
            { BVT      -> move! }
            { BCR      -> move! }
            { BHASH    -> skip-comment! }
            { BCOMMA   -> close-colons! TokenValue.Comma emit! move! }
            { BRPAREN  -> close-colons! emit-rparen!  move! }
            { BRSQUARE -> close-colons! emit-rsquare! move! }
            { BRCURLY  -> close-colons! emit-rcurly!  move! }
            { BCOLON   -> prepare-for-args! emit-lcolon!  move! }
            { BLPAREN  -> prepare-for-args! emit-lparen!  move! }
            { BLSQUARE -> prepare-for-atom! emit-lsquare! move! }
            { BLCURLY  -> prepare-for-atom! emit-lcurly!  move! }
            { BQUOTE   -> prepare-for-atom! emit-string!  move! }
            { BNUL     -> }
            { _ ->
                is-name-byte if(
                    prepare-for-atom! emit-name!,
                    "Unrecognized byte." +Lexer.fatal-error!
                )
            }
        }
    }

    def close-colons! [ +Mirth +Lexer |- ] {
        while-some(
            stack-peek rdip:filter(lcolon-open?),
            stack-drop
            dup TokenValue.RColon make!
            TokenValue.LColon swap ~value !
        )
    }

    def prepare-for-atom! [ +Mirth +Lexer |- ] {
        lexer-last-token rdip:lcolon-open? else(close-colons!)
    }
    def prepare-for-args! [ +Mirth +Lexer |- ] {
        lexer-last-token rdip:can-take-args? else(close-colons!)
    }

    def emit-lcolon!  [ +Lexer |- ] { TokenValue.LColonOpen  make! stack-push! }
    def emit-lparen!  [ +Lexer |- ] { TokenValue.LParenOpen  make! stack-push! }
    def emit-lcurly!  [ +Lexer |- ] { TokenValue.LCurlyOpen  make! stack-push! }
    def emit-lsquare! [ +Lexer |- ] { TokenValue.LSquareOpen make! stack-push! }

    def emit-rparen! [ +Mirth +Lexer |- ] {
        stack-pop! rdip:filter(value lparen-open?)
        unwrap("Mismatched right parenthesis." +Lexer.fatal-error!)
        dup TokenValue.RParen make!
        TokenValue.LParen swap ~value !
    }

    def emit-rcurly! [ +Mirth +Lexer |- ] {
        stack-pop! rdip:filter(value lcurly-open?)
        unwrap("Mismatched right curly brace." +Lexer.fatal-error!)
        dup TokenValue.RCurly make!
        TokenValue.LCurly swap ~value !
    }

    def emit-rsquare! [ +Mirth +Lexer |- ] {
        stack-pop! rdip:filter(value lsquare-open?)
        unwrap("Mismatched right square bracket." +Lexer.fatal-error!)
        dup TokenValue.RSquare make!
        TokenValue.LSquare swap ~value !
    }

    def emit-name! [ +Mirth +Lexer |- ] {
        rdip("" thaw)
        lexer-module
        lexer-row
        lexer-col

        peek while(dup is-name-byte,
            rdip(push-byte-unsafe!)
            move! peek
        )
        drop

        rdip:is-doc-start? if(
            drop3
            skip-doc!,

            Token.alloc!
            tuck ~col !
            tuck ~row !
            tuck ~module !

            >+lexer
            float-token? map(Ok)
            or?(int-token?)
            or?(dname-token? map(Ok))
            or?(label-token? map(Ok))
            else?(name-token Ok)
            else(rdip:fatal-error!)
            over ~value !
            +lexer>
            lexer-doc over ~doc !

            lexer-last-token!
            None lexer-doc!
        )
        rdip(freeze drop)
    }

    def emit-string! [ +Mirth +Lexer |- ] {
        rdip("" thaw)
        emit! (
            move!
            peek while(dup is-string-end not,
                push-string-byte!
                move! peek
            )
            Byte.BQUOTE = else(
                "String literal is missing end quote (\")."
                rdip_:+Lexer.fatal-error!
            )

            rdip:freeze TokenValue.Str
        )
    }

    def push-string-byte! [ +Mirth +Str +Lexer |- Byte -- ] {
        { B'\' -> move! peek push-string-escape-byte! }
        { _ -> rdip:push-byte-unsafe! }
    }

    def push-string-escape-byte! [ +Mirth +Str +Lexer |- Byte -- ] {
        { BLF -> newline! }
        { B'n' -> Byte.BLF rdip(push-byte-ascii!) }
        { B'r' -> Byte.BCR rdip(push-byte-ascii!) }
        { B't' -> Byte.BHT rdip(push-byte-ascii!) }
        { B'\' -> Byte.B'\' rdip(push-byte-ascii!) }
        { BQUOTE -> Byte.BQUOTE rdip(push-byte-ascii!) }
        { _ ->
            rdip(push-byte-unsafe!)
            "Unknown character escape sequence." rdip_:+Lexer.warning!
        }
    }

    def skip-comment! [ +Lexer |- ] {
        while(comment-end? not, move!)
        peek Byte.BLF = then(newline! move!)
    }

    def skip-doc! [ +Lexer |- ] {
        lexer-doc else?("") rdip:thaw
        while(comment-end? not, peek rdip:push-byte-ascii! move!)
        peek Byte.BLF = then(newline! peek rdip:push-byte-ascii! move!)
        rdip:freeze Some
        lexer-doc!
    }

    def comment-end? [ +Lexer |- Bool ] {
        done? or(peek Byte.BLF =)
    }

}

def run-lexer! [ +World +Mirth |- Path -- Module ] {
    Module.New! dup source-path
    rdip:read-path! else(io-error!)
    >content +Lexer.Start!
    while(done? not, next!)
    stop!
}

def +Str.name-token [ +Mirth +Str |- TokenValue ] { dup! rdip:>Name TokenValue.Name }

def +Str.first-byte  [ +Str |- Byte ] { 0 Offset byte@ }
def +Str.second-byte [ +Str |- Byte ] { 1 Offset byte@ }
def +Str.third-byte  [ +Str |- Byte ] { 2 Offset byte@ }

def +Str.first-two-bytes [ +Str +Unsafe |- Str ] { 2 bytes +Str.take-slice }
def +Str.last-two-bytes  [ +Str +Unsafe |- Str ] { rdip:num-bytes? 2 bytes - offset +Str.drop-slice }

def +Str.drop-first-byte [ +Str +Unsafe |- Str ] { 1 Offset +Str.drop-slice }
def +Str.drop-first-two-bytes [ +Str +Unsafe |- Str ] { 2 Offset +Str.drop-slice }
def +Str.drop-last-byte [ +Str +Unsafe |- Str ] { rdip:num-bytes? 1B- +Str.take-slice }
def +Str.drop-last-two-bytes [ +Str +Unsafe |- Str ] { rdip:num-bytes? 2 bytes - +Str.take-slice }

def +Str.label-token? [ +Mirth +Str |- Maybe(TokenValue) ] {
    label-push-token?
    or?(label-push-r-token?)
    or?(label-pop-token?)
    or?(label-pop-r-token?)
    or?(label-get-token?)
    or?(label-set-token?)
}

def +Str.label-pop-token? [ +Mirth +Str |- Maybe(TokenValue) ] {
    first-byte is-lower and(last-byte Byte.B'>' =) if(
        unsafe(+Str.drop-last-byte) rdip(>Name Label.new!) TokenValue.LabelPop Some,
        None
    )
}

def +Str.label-pop-r-token? [ +Mirth +Str |- Maybe(TokenValue) ] {
    first-byte Byte.B'+' = and(second-byte is-lower and(last-byte Byte.B'>' =)) if(
        unsafe(+Str.drop-last-byte) rdip(>Name Label.new!) TokenValue.LabelPopR Some,
        None
    )
}

def +Str.label-push-token? [ +Mirth +Str |- Maybe(TokenValue) ] {
    first-byte Byte.B'>' = and(second-byte is-lower) if(
        unsafe(+Str.drop-first-byte) rdip(>Name Label.new!) TokenValue.LabelPush Some,
        None
    )
}

def +Str.label-push-r-token? [ +Mirth +Str |- Maybe(TokenValue) ] {
    unsafe(+Str.first-two-bytes) ">+" = and(third-byte is-lower) if(
        unsafe(+Str.drop-first-byte) rdip(>Name Label.new!) TokenValue.LabelPushR Some,
        None
    )
}

def +Str.label-get-token? [ +Mirth +Str |- Maybe(TokenValue) ] {
    first-byte Byte.B'@' = and(second-byte is-lower or(second-byte Byte.B'+' = and(third-byte is-lower))) if(
        unsafe(+Str.drop-first-byte) rdip(>Name Label.new!) TokenValue.LabelGet Some,
        None
    )
}

def +Str.label-set-token? [ +Mirth +Str |- Maybe(TokenValue) ] {
    first-byte Byte.B'!' = and(second-byte is-lower or(second-byte Byte.B'+' = and(third-byte is-lower))) if(
        unsafe(+Str.drop-first-byte) rdip(>Name Label.new!) TokenValue.LabelSet Some,
        None
    )
}

def +Str.dname-token? [ +Mirth +Str |- Maybe(TokenValue) ] {
    Byte.BDOT +Str.split-byte
    uncons >Nest? match {
        { None -> drop None }
        { Some ->
            dip(dup Str.empty? if(drop None, rdip:>Name Some))
            map(rdip:>Name) DName TokenValue.DName Some
        }
    }
}

def +Str.is-doc-start? [ +Str |- Bool ] { dup! "|||" = }
def +Str.is-arrow?     [ +Str |- Bool ] { dup! "->" = }
def +Str.is-dashes?    [ +Str |- Bool ] { dup! "--" = }

def +Str.is-float? [ +Str |- Bool ] {
    0 Size
    0 Offset

    dup byte@ is-sign if(1B+, id)

    while(dup byte@ is-digit, dip(1B+) 1B+)

    dup byte@ Byte.BDOT = if(
        dip(1B+) 1B+ while(dup byte@ is-digit, dip(1B+) 1B+)
        dip(3 bytes >=) num-bytes? = and,
        drop2 False
    )
}

def +Str.float-token? [ +Mirth +Str Token |- Maybe(TokenValue) ] {
    is-float? >Maybe (
        dup! >F64? unwrap(
            "[lexer] bug: failed to parse float literal" rdip:emit-fatal-error!
        ) TokenValue.F64
    )
}

||| Process float sign and return initial state for rest float lexing.
||| returns: (sign multiplier) (str-buf index)
def +Str.float-sign [ +Str |- Byte Offset ] {
    0 Offset byte@ byte-sign-value-index-float
}

def byte-sign-value-index-float [ Byte -- Byte Offset ] {
    { B'-' -> Byte.B'-' 1 Offset }
    { B'+' -> Byte.B'+' 1 Offset }
    { _ -> drop Byte.B'+' 0 Offset }
}

def +Str.int-token? [ +Str |- Maybe(Result(Str, TokenValue)) ] {
    None
    or?(is-dec-int? >Maybe:dec-int?)
    or?(is-hex-int? >Maybe:hex-int?)
    or?(is-oct-int? >Maybe:oct-int?)
}

data IntSuffix {
    Int
    U8 U16 U32 U64
    I8 I16 I32 I64
    --
    def convert [ Int IntSuffix -- Result(Str, TokenValue) ] {
        { Int -> TokenValue.Int Ok }
        { U8  -> >U8-if (TokenValue.U8  Ok, Str(int; " is outside of U8 range." ;) Err) }
        { U16 -> >U16-if(TokenValue.U16 Ok, Str(int; " is outside of U16 range.";) Err) }
        { U32 -> >U32-if(TokenValue.U32 Ok, Str(int; " is outside of U32 range.";) Err) }
        { U64 -> >U64-if(TokenValue.U64 Ok, Str(int; " is outside of U64 range.";) Err) }
        { I8  -> >I8-if (TokenValue.I8  Ok, Str(int; " is outside of I8 range." ;) Err) }
        { I16 -> >I16-if(TokenValue.I16 Ok, Str(int; " is outside of I16 range.";) Err) }
        { I32 -> >I32-if(TokenValue.I32 Ok, Str(int; " is outside of I32 range.";) Err) }
        { I64 -> >I64-if(TokenValue.I64 Ok, Str(int; " is outside of I64 range.";) Err) }
    }
}

def +Str.int-suffix? [ +Str |- Offset -- Maybe(IntSuffix) ] {
    unsafe(+Str.drop-slice) >suffix
    None
    or?(@suffix "" = >Maybe(IntSuffix.Int))
    or?(@suffix "u8" = >Maybe(IntSuffix.U8))
    or?(@suffix "u16" = >Maybe(IntSuffix.U16))
    or?(@suffix "u32" = >Maybe(IntSuffix.U32))
    or?(@suffix "u64" = >Maybe(IntSuffix.U64))
    or?(@suffix "i8" = >Maybe(IntSuffix.I8))
    or?(@suffix "i16" = >Maybe(IntSuffix.I16))
    or?(@suffix "i32" = >Maybe(IntSuffix.I32))
    or?(@suffix "i64" = >Maybe(IntSuffix.I64))
    suffix> drop
}

def skipping-underscore(f) [ (Byte -- Bool) +Str |- Size Offset -- Size Offset Bool ] {
    over 0B> and(dup byte@ Byte.B'_' =) and(dup 1B+ byte@ f) if(1B+ True, dup byte@ f)
}

def +Str.is-dec-int? [ +Str |- Bool ] {
    0 Size # number of digits
    0 Offset # current index
    dup byte@ is-sign if(1B+, id)
    while(skipping-underscore:is-digit, dip(1B+) 1B+)
    swap 0B> and(dup int-suffix? some?) nip
}

def +Str.is-hex-int? [ +Str |- Bool ] {
    0 Size # number of digits
    0 Offset # current index
    dup byte@ is-sign if(
        1B+,
        id
    )
    dup byte@ Byte.B'0' = if(
        1B+
        dup byte@ Byte.B'x' = if(
            1B+
            while(skipping-underscore:is-hexdigit, dip(1B+) 1B+)
            swap 0B> and(dup int-suffix? some?) nip,

            drop2 False
        ),

        drop2 False
    )
}

def +Str.is-oct-int? [ +Str |- Bool ] {
    0 Size # number of digits
    0 Offset # current index
    dup byte@ is-sign if(
        1B+,
        id
    )
    dup byte@ Byte.B'0' = if(
        1B+
        dup byte@ Byte.B'o' = if(
            1B+
            while(skipping-underscore:is-octdigit, dip(1B+) 1B+)
            swap 0B> and(dup int-suffix? some?) nip,

            drop2 False
        ),

        drop2 False
    )
}

||| process int sign and return initial state for rest of int lexing.
||| returns: (sign multiplier) (accumulated value = 0) (str-buf index)
def +Str.int-sign [ +Str |- Int Int Offset ] {
    0 Offset byte@ byte-sign-value-index
}

def byte-sign-value-index [ Byte -- Int Int Offset ] {
    { B'-' -> -1 0 1 Offset }
    { B'+' -> +1 0 1 Offset }
    { _ -> drop +1 0 0 Offset }
}

def +Str.finish-int-literal [ +Str |- Int Int Offset -- Result(Str, TokenValue) ] {
    dip:*
    int-suffix? if?(
        convert,
        drop "Invalid integer token." Err
    )
}

def +Str.dec-int? [ +Str |- Result(Str, TokenValue) ] {
    int-sign
    while(
        dup byte@ Byte.B'_' = then(1B+)
        dup byte@ is-digit,
        sip(
            byte@ >Int
            dip(10 *) 48 - +
        )
        1B+)
    finish-int-literal
}

def +Str.hex-int? [ +Str |- Result(Str, TokenValue) ] {
    int-sign 2 bytes + # skip 0x prefix
    while(
        dup byte@ Byte.B'_' = then(1B+)
        dup byte@ is-hexdigit,
        sip(
            byte@
            dip(16 *) hexdigit-value +
        )
        1B+)
    finish-int-literal
}

def +Str.oct-int? [ +Str |- Result(Str, TokenValue) ] {
    int-sign 2 bytes + # skip 0o prefix
    while(
        dup byte@ Byte.B'_' = then(1B+)
        dup byte@ is-octdigit,
        sip(
            byte@ >Int
            dip(8 *) 48 - +
        )
        1B+)
    finish-int-literal
}

def hexdigit-value [ Byte -- Int ] {
    dup is-digit if(
        >Int 48 -,
        to-upper >Int 55 -
    )
}
