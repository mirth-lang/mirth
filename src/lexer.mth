module mirth.lexer

import std.prelude
import std.byte
import std.path
import std.str
import std.maybe
import std.result
import std.list
import std.ctypes
import std.world
import std.file
import std.input
import std.unicode

import mirth.location
import mirth.name
import mirth.label
import mirth.token
import mirth.mirth
import mirth.module

#########
# LEXER #
#########

struct +Lexer {
    lexer-module:Module
    lexer-row:Row
    lexer-col:Col
    lexer-doc:Maybe(Str)
    lexer-stack:List(Token)
    lexer-first-token:Token
    lexer-last-token:Token
    lexer-source: Str
    lexer-offset: Offset
    --
    def stack-push! [ +Lexer |- Token -- ] { lexer-stack:cons }
    def stack-pop!  [ +Lexer |- Maybe(Token) ] { lexer-stack:uncons }
    def stack-drop  [ +Lexer |- ] { lexer-stack:tail }
    def stack-peek  [ +Lexer |- Maybe(Token) ] { lexer-stack head }

    def Start! [ +Mirth |- source:Str Module -- +Lexer ] {
        >lexer-module
        source> >lexer-source
        0 >Offset >lexer-offset
        1 Row >lexer-row
        1 Col >lexer-col
        None >lexer-doc
        L0 >lexer-stack
        Token.alloc-none! dup
        >lexer-first-token
        >lexer-last-token
        +Lexer
    }

    def stop! [ +Mirth |- +Lexer -- Module ] {
        TokenValue.None emit!
        /+Lexer
        lexer-stack> uncons drop for("Mismatched token." emit-fatal-error!)
        lexer-row> lexer-col> lexer-last-token> drop3
        lexer-module> Token.alloc-none! over end!
        lexer-first-token> succ over start!
        lexer-doc> drop
        lexer-source> drop
        lexer-offset> drop
    }

    def lexer-location [ +Lexer |- Location ] {
        lexer-module >module
        lexer-row >row
        lexer-col >col
        Location
    }
    def lexer-warning! [ +Mirth +Lexer |- Str -- ] { dip:lexer-location emit-warning-at! }
    def lexer-error! [ +Mirth +Lexer |- Str -- ] { dip:lexer-location emit-error-at! }
    def lexer-fatal-error! [ *a Str +Mirth +Lexer -- *b ] { dip:lexer-location rswap emit-fatal-error-at! }

    def done? [ +Lexer |- Bool ] { lexer-source num-bytes lexer-offset <= }
    def peek  [ +Lexer |- Byte ] { lexer-offset lexer-source byte@ }
    def move! [ +Lexer |- ] { lexer-offset:1B+ lexer-col:1+ }
    def newline! [ +Lexer |- ] { 0 Col lexer-col! lexer-row:1+ }

    ||| Create a token at the current location with the given payload.
    def make! [ +Lexer |- TokenValue -- Token ] {
        Token.alloc!
        tuck ~value !
        lexer-module over ~module !
        lexer-row over ~row !
        lexer-col over ~col !
        lexer-doc over ~doc !
        None lexer-doc!
        dup lexer-last-token!
    }

    ||| Create a token at the current location, and then build the payload (while consuming characters).
    def make!(f) [ +Lexer |- ( *a -- *b TokenValue ) *a -- *b Token ] {
        TokenValue.None make!
        dip:f
        tuck ~value !
    }

    ||| Emit a token at the current location with the given payload. Same as make! but drops the token.
    def emit! [ +Lexer |- TokenValue -- ] { make! drop }

    ||| Create a token at the current location, then build the payload. Same as make!(f) but drops the token.
    def emit!(f) { make!(f) drop }

    ||| Analyze the next byte (and next token).
    def next! [ +Mirth +Lexer |- ] {
        peek match {
            { BLF      -> newline! move! }
            { BSPACE   -> move! }
            { BHT      -> move! }
            { BVT      -> move! }
            { BCR      -> move! }
            { BHASH    -> skip-comment! }
            { BCOMMA   -> close-colons! TokenValue.Comma emit! move! }
            { BRPAREN  -> close-colons! emit-rparen!  move! }
            { BRSQUARE -> close-colons! emit-rsquare! move! }
            { BRCURLY  -> close-colons! emit-rcurly!  move! }
            { BCOLON   -> prepare-for-args! emit-lcolon!  move! }
            { BLPAREN  -> prepare-for-args! emit-lparen!  move! }
            { BLSQUARE -> prepare-for-atom! emit-lsquare! move! }
            { BLCURLY  -> prepare-for-atom! emit-lcurly!  move! }
            { BQUOTE   -> prepare-for-atom! emit-string!  move! }
            { BNUL     -> }
            { _ ->
                is-name-byte if(
                    prepare-for-atom! emit-name!,
                    "Unrecognized byte." lexer-fatal-error!
                )
            }
        }
    }

    def close-colons! [ +Mirth +Lexer |- ] {
        while-some(
            stack-peek filter(lcolon-open?),
            stack-drop
            dup TokenValue.RColon make!
            TokenValue.LColon swap ~value !
        )
    }

    def prepare-for-atom! [ +Mirth +Lexer |- ] {
        lexer-last-token lcolon-open? else(close-colons!)
    }
    def prepare-for-args! [ +Mirth +Lexer |- ] {
        lexer-last-token can-take-args? else(close-colons!)
    }

    def emit-lcolon!  [ +Lexer |- ] { TokenValue.LColonOpen  make! stack-push! }
    def emit-lparen!  [ +Lexer |- ] { TokenValue.LParenOpen  make! stack-push! }
    def emit-lcurly!  [ +Lexer |- ] { TokenValue.LCurlyOpen  make! stack-push! }
    def emit-lsquare! [ +Lexer |- ] { TokenValue.LSquareOpen make! stack-push! }

    def emit-rparen! [ +Mirth +Lexer |- ] {
        stack-pop! filter(value lparen-open?)
        unwrap("Mismatched right parenthesis." lexer-fatal-error!)
        dup TokenValue.RParen make!
        TokenValue.LParen swap ~value !
    }

    def emit-rcurly! [ +Mirth +Lexer |- ] {
        stack-pop! filter(value lcurly-open?)
        unwrap("Mismatched right curly brace." lexer-fatal-error!)
        dup TokenValue.RCurly make!
        TokenValue.LCurly swap ~value !
    }

    def emit-rsquare! [ +Mirth +Lexer |- ] {
        stack-pop! filter(value lsquare-open?)
        unwrap("Mismatched right square bracket." lexer-fatal-error!)
        dup TokenValue.RSquare make!
        TokenValue.LSquare swap ~value !
    }

    def emit-name! [ +Mirth +Lexer |- ] {
        lexer-module
        lexer-row
        lexer-col

        Str(
            peek while(dup is-name-byte,
                push-byte-unsafe!
                move! peek
            )
            drop

            is-doc-start? if(
                drop3
                skip-doc!,

                Token.alloc!
                tuck ~col !
                tuck ~row !
                tuck ~module !

                float-token? map(Ok)
                or?(int-token?)
                or?(dname-token? map(Ok))
                or?(label-token? map(Ok))
                else?(name-token Ok)
                else(emit-fatal-error!)
                over ~value !

                lexer-doc over ~doc !

                lexer-last-token!
                None lexer-doc!
            )
        ) drop
    }

    def emit-string! [ +Mirth +Lexer |- ] {
        emit! (
            move! Str(
                peek while(dup is-string-end not,
                    push-string-byte!
                    move! peek
                )
                Byte.BQUOTE = else(
                    "String literal is missing end quote (\")."
                    lexer-fatal-error!
                )
            ) TokenValue.Str
        )
    }

    def push-string-byte! [ +Mirth +Str +Lexer |- Byte -- ] {
        { B'\' -> move! peek push-string-escape-byte! }
        { _ -> push-byte-unsafe! }
    }

    def push-string-escape-byte! [ +Mirth +Str +Lexer |- Byte -- ] {
        { BLF -> newline! }
        { B'n' -> Byte.BLF push-byte-ascii! }
        { B'r' -> Byte.BCR push-byte-ascii! }
        { B't' -> Byte.BHT push-byte-ascii! }
        { B'\' -> Byte.B'\' push-byte-ascii! }
        { BQUOTE -> Byte.BQUOTE push-byte-ascii! }
        { _ ->
            push-byte-unsafe!
            "Unknown character escape sequence." lexer-warning!
        }
    }

    def skip-comment! [ +Lexer |- ] {
        while(comment-end? not, move!)
        peek Byte.BLF = then(newline! move!)
    }

    def skip-doc! [ +Lexer |- ] {
        lexer-doc else?("") thaw
        while(comment-end? not, peek push-byte-ascii! move!)
        peek Byte.BLF = then(newline! peek push-byte-ascii! move!)
        freeze Some lexer-doc!
    }

    def comment-end? [ +Lexer |- Bool ] {
        done? or(peek Byte.BLF =)
    }

    def name-token [ +Mirth +Str +Lexer |- TokenValue ] { dup! Name TokenValue.Name }

    def label-token? [ +Mirth +Str +Lexer |- Maybe(TokenValue) ] {
        label-push-token?
        or?(label-push-r-token?)
        or?(label-pop-token?)
        or?(label-pop-r-token?)
        or?(label-get-token?)
        or?(label-set-token?)
    }

    def label-pop-token? [ +Mirth +Str +Lexer |- Maybe(TokenValue) ] {
        first-byte is-lower and(last-byte Byte.B'>' =) if(
            unsafe:drop-last-byte Name Label TokenValue.LabelPop Some,
            None
        )
    }

    def label-pop-r-token? [ +Mirth +Str +Lexer |- Maybe(TokenValue) ] {
        first-byte Byte.B'+' = and(second-byte is-lower and(last-byte Byte.B'>' =)) if(
            unsafe:drop-last-byte Name Label TokenValue.LabelPopR Some,
            None
        )
    }

    def label-push-token? [ +Mirth +Str +Lexer |- Maybe(TokenValue) ] {
        first-byte Byte.B'>' = and(second-byte is-lower) if(
            unsafe:drop-first-byte Name Label TokenValue.LabelPush Some,
            None
        )
    }

    def label-push-r-token? [ +Mirth +Str +Lexer |- Maybe(TokenValue) ] {
        unsafe:first-two-bytes ">+" = and(third-byte is-lower) if(
            unsafe:drop-first-byte Name Label TokenValue.LabelPushR Some,
            None
        )
    }

    def label-get-token? [ +Mirth +Str +Lexer |- Maybe(TokenValue) ] {
        first-byte Byte.B'@' = and(second-byte is-lower or(second-byte Byte.B'+' = and(third-byte is-lower))) if(
            unsafe:drop-first-byte Name Label TokenValue.LabelGet Some,
            None
        )
    }

    def label-set-token? [ +Mirth +Str +Lexer |- Maybe(TokenValue) ] {
        first-byte Byte.B'!' = and(second-byte is-lower or(second-byte Byte.B'+' = and(third-byte is-lower))) if(
            unsafe:drop-first-byte Name Label TokenValue.LabelSet Some,
            None
        )
    }

    def dname-token? [ +Mirth +Str +Lexer |- Maybe(TokenValue) ] {
        Byte.BDOT +Str.split-byte
        uncons >Nest? match {
            { None -> drop None }
            { Some ->
                dip(dup Str.empty? if(drop None, Name Some))
                map(Name) DName TokenValue.DName Some
            }
        }
    }

    def is-doc-start? [ +Str +Lexer |- Bool ] { dup! "|||" = }
    def is-arrow?     [ +Str +Lexer |- Bool ] { dup! "->" = }
    def is-dashes?    [ +Str +Lexer |- Bool ] { dup! "--" = }

    def is-float? [ +Str +Lexer |- Bool ] {
        0 Size
        0 Offset

        dup byte@ is-sign if(1B+, id)

        while(dup byte@ is-digit, dip(1B+) 1B+)

        dup byte@ Byte.BDOT = if(
            dip(1B+) 1B+ while(dup byte@ is-digit, dip(1B+) 1B+)
            dip(3 bytes >=) num-bytes? = and,
            drop2 False
        )
    }

    def float-token? [ +Mirth +Str +Lexer Token |- Maybe(TokenValue) ] {
        is-float? >Maybe (
            dup! >F64? unwrap(
                "[lexer] bug: failed to parse float literal" emit-fatal-error!
            ) TokenValue.F64
        )
    }

    ||| Process float sign and return initial state for rest float lexing.
    ||| returns: (sign multiplier) (str-buf index)
    def float-sign [ +Str +Lexer |- Byte Offset ] {
        0 Offset byte@ byte-sign-value-index-float
    }

    def byte-sign-value-index-float [ Byte -- Byte Offset ] {
        { B'-' -> Byte.B'-' 1 Offset }
        { B'+' -> Byte.B'+' 1 Offset }
        { _ -> drop Byte.B'+' 0 Offset }
    }

    def int-token? [ +Str +Lexer |- Maybe(Result(Str, TokenValue)) ] {
        None
        or?(is-dec-int? >Maybe:dec-int?)
        or?(is-hex-int? >Maybe:hex-int?)
        or?(is-oct-int? >Maybe:oct-int?)
    }

    def int-suffix? [ +Str +Lexer |- Offset -- Maybe(IntSuffix) ] {
        unsafe(+Str.drop-slice) >suffix
        None
        or?(@suffix "" = >Maybe(IntSuffix.Int))
        or?(@suffix "u8" = >Maybe(IntSuffix.U8))
        or?(@suffix "u16" = >Maybe(IntSuffix.U16))
        or?(@suffix "u32" = >Maybe(IntSuffix.U32))
        or?(@suffix "u64" = >Maybe(IntSuffix.U64))
        or?(@suffix "i8" = >Maybe(IntSuffix.I8))
        or?(@suffix "i16" = >Maybe(IntSuffix.I16))
        or?(@suffix "i32" = >Maybe(IntSuffix.I32))
        or?(@suffix "i64" = >Maybe(IntSuffix.I64))
        suffix> drop
    }

    def skipping-underscore(f) [ (Byte -- Bool) +Str +Lexer |- Size Offset -- Size Offset Bool ] {
        over 0B> and(dup byte@ Byte.B'_' =) and(dup 1B+ byte@ f) if(1B+ True, dup byte@ f)
    }

    def is-dec-int? [ +Str +Lexer |- Bool ] {
        0 Size # number of digits
        0 Offset # current index
        dup byte@ is-sign if(1B+, id)
        while(skipping-underscore:is-digit, dip(1B+) 1B+)
        swap 0B> and(dup int-suffix? some?) nip
    }

    def is-hex-int? [ +Str +Lexer |- Bool ] {
        0 Size # number of digits
        0 Offset # current index
        dup byte@ is-sign if(
            1B+,
            id
        )
        dup byte@ Byte.B'0' = if(
            1B+
            dup byte@ Byte.B'x' = if(
                1B+
                while(skipping-underscore:is-hexdigit, dip(1B+) 1B+)
                swap 0B> and(dup int-suffix? some?) nip,

                drop2 False
            ),

            drop2 False
        )
    }

    def is-oct-int? [ +Str +Lexer |- Bool ] {
        0 Size # number of digits
        0 Offset # current index
        dup byte@ is-sign if(
            1B+,
            id
        )
        dup byte@ Byte.B'0' = if(
            1B+
            dup byte@ Byte.B'o' = if(
                1B+
                while(skipping-underscore:is-octdigit, dip(1B+) 1B+)
                swap 0B> and(dup int-suffix? some?) nip,

                drop2 False
            ),

            drop2 False
        )
    }

    ||| process int sign and return initial state for rest of int lexing.
    ||| returns: (sign multiplier) (accumulated value = 0) (str-buf index)
    def int-sign [ +Str +Lexer |- Int Int Offset ] {
        0 Offset byte@ byte-sign-value-index
    }

    def byte-sign-value-index [ Byte -- Int Int Offset ] {
        { B'-' -> -1 0 1 Offset }
        { B'+' -> +1 0 1 Offset }
        { _ -> drop +1 0 0 Offset }
    }

    def finish-int-literal [ +Str +Lexer |- Int Int Offset -- Result(Str, TokenValue) ] {
        dip:*
        int-suffix? if?(
            convert,
            drop "Invalid integer token." Err
        )
    }

    def dec-int? [ +Str +Lexer |- Result(Str, TokenValue) ] {
        int-sign
        while(
            dup byte@ Byte.B'_' = then(1B+)
            dup byte@ is-digit,
            sip(
                byte@ >Int
                dip(10 *) 48 - +
            )
            1B+)
        finish-int-literal
    }

    def hex-int? [ +Str +Lexer |- Result(Str, TokenValue) ] {
        int-sign 2 bytes + # skip 0x prefix
        while(
            dup byte@ Byte.B'_' = then(1B+)
            dup byte@ is-hexdigit,
            sip(
                byte@
                dip(16 *) hexdigit-value +
            )
            1B+)
        finish-int-literal
    }

    def oct-int? [ +Str +Lexer |- Result(Str, TokenValue) ] {
        int-sign 2 bytes + # skip 0o prefix
        while(
            dup byte@ Byte.B'_' = then(1B+)
            dup byte@ is-octdigit,
            sip(
                byte@ >Int
                dip(8 *) 48 - +
            )
            1B+)
        finish-int-literal
    }

    def hexdigit-value [ Byte -- Int ] {
        dup is-digit if(
            >Int 48 -,
            to-upper >Int 55 -
        )
    }
}

data IntSuffix {
    Int
    U8 U16 U32 U64
    I8 I16 I32 I64
    --
    def convert [ Int IntSuffix -- Result(Str, TokenValue) ] {
        { Int -> TokenValue.Int Ok }
        { U8  -> >U8-if (TokenValue.U8  Ok, Str(int; " is outside of U8 range." ;) Err) }
        { U16 -> >U16-if(TokenValue.U16 Ok, Str(int; " is outside of U16 range.";) Err) }
        { U32 -> >U32-if(TokenValue.U32 Ok, Str(int; " is outside of U32 range.";) Err) }
        { U64 -> >U64-if(TokenValue.U64 Ok, Str(int; " is outside of U64 range.";) Err) }
        { I8  -> >I8-if (TokenValue.I8  Ok, Str(int; " is outside of I8 range." ;) Err) }
        { I16 -> >I16-if(TokenValue.I16 Ok, Str(int; " is outside of I16 range.";) Err) }
        { I32 -> >I32-if(TokenValue.I32 Ok, Str(int; " is outside of I32 range.";) Err) }
        { I64 -> >I64-if(TokenValue.I64 Ok, Str(int; " is outside of I64 range.";) Err) }
    }
}

def +Mirth.run-lexer! [ +World +Mirth |- Path -- Module ] {
    Module.New!
    dup source-path read-path! if(
        >source +Lexer.Start!
        while(done? not, next!)
        stop!,

        io-error!
    )
}
