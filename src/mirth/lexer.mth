# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at https://mozilla.org/MPL/2.0/.

import base/panic
import base/int
import base/nat
import base/pos
import base/char
import base/order
import base/list
import base/str
import base/regex+
import base/maybe
import base/result
import mirth/mod
import mirth/loc
import mirth/token

export mirth/lexer
  type LexerError
  type Token
  type Mod
  type Result(a,b)
  type L(t)
  lexerError->str : LexerError -- Str
  tokenize : Mod Str -- Result(LexerError, List(L(Token)))
end

#
# auxiliary lexing functions
#

digitVal : Char -- Int
digitVal =
  cond(
    isdigit? -> char->int "0" str->char char->int z-,
    islower? -> char->int "a" str->char char->int z- 10 z+,
    isupper? -> char->int "A" str->char char->int z- 10 z+,
    drop 0
  )

hassign? : Str -- Str Bool
hassign? = dup n1 strtakeL cond(
  dup "-" streq -> drop true,
  dup "+" streq -> drop true,
  drop false
)
hassign? drop == id

readInt(base: Int) : Str -- Int
readInt(base) =
  hassign? if(
    n1 strbreak readInt(base)
    swap "-" streq if(zneg, id),
    dip(0) strfold(dip(base z*) digitVal z+)
  )

readDecInt : Str -- Int
readHexInt : Str -- Int
readDecInt = readInt(10)
readHexInt = n2 strdropL readInt(16)

int->str readDecInt == id

wordToken : Str -- Token  # basically TNAME but separates out reserved words.
wordToken =
  cond(
    dup "="      streq -> drop TEQUAL,
    dup "=="     streq -> drop TEQUAL2,
    dup "--"     streq -> drop TDASH2,
    dup "import" streq -> drop TIMPORT,
    dup "export" streq -> drop TEXPORT,
    dup "type"   streq -> drop TTYPE,
    dup "data"   streq -> drop TDATA,
    dup "end"    streq -> drop TEND,
    TNAME
  )

isEscapeChar? : Char -- Char Bool
isEscapeChar? = dup "\\" str->char chareq

interpretEscapedChar : Char -- Char
interpretEscapedChar =
  cond(
    dup "n" str->char chareq -> drop "\n" str->char,
    dup "r" str->char chareq -> drop "\r" str->char,
    dup "t" str->char chareq -> drop "\t" str->char,
    id
  )

readStringBody : Str -- Str
readStringBody = dip("" false) strfold(
  swap if(
    interpretEscapedChar char->str <> false,
    cond(
      isEscapeChar? -> drop true,
      char->str <> false
    )
  )
) drop

"nrt" readStringBody == "nrt"
"\\n\\r\\t\\\\\\\"" readStringBody == "\n\r\t\\\""
# TODO: Add unicode support \u0000.

readString : Str -- Str
readString = n1 strdropL n1 strdropR readStringBody

readMultistring : Str -- Str
readMultistring = 3 znat strdropL 3 znat strdropR readStringBody

readDoc : Str -- Str
readDoc = 3 znat strbreak nip n1 strbreak over " " streq if(nip, <>)

#
# regexes
#

decIntRegex : Regex
decIntRegex = "" lit "+-" cls alt2 "0123456789" cls plus seq2

hexIntRegex : Regex
hexIntRegex = "" lit "+-" cls alt2 "0" lit "xX" cls "0123456789abcdefABCDEF" cls plus seq4

wordRegex : Regex
wordRegex = "0123456789abcdefghijklmnopqrstuvwxyzzABCDEFGHIJKLMNOPQRSTUVWXYZ_-?+*~!@$%^&=/|<>'.\\" cls plus

stringChar : Regex
stringChar = "\t !#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~" cls "\\" lit "ntr\\\"" cls seq2 alt2

stringRegex : Regex
stringRegex = "\"" lit stringChar star "\"" lit seq3

multistringChar : Regex
multistringChar = stringChar "\n" lit alt2

multistringAtom : Regex
multistringAtom = multistringChar "\"" lit multistringChar "\"" lit multistringChar seq2 alt2 seq2 alt2

multistringRegex : Regex
multistringRegex = "\"\"\"" lit multistringAtom star "\"\"\"" lit seq3

visibleChar : Regex
visibleChar = "\t !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~" cls

commentRegex : Regex
commentRegex = "#" lit visibleChar star seq2

trimRegex : Regex
trimRegex = " \t" cls star

newlineRegex : Regex
newlineRegex = commentRegex "\r\n" cls trimRegex seq2 alt2 plus

docRegex : Regex
docRegex = "|||" lit visibleChar star seq2

#
#
#

data LexerRule
  lexerRule(f: Str -- Token) : Str -- LexerRule
end

lexerRules : List(LexerRule)
lexerRules = $(
  nil

  # literals
  "\\(" lexerRule(drop TLPAREN) cons
  "\\)" lexerRule(drop TRPAREN) cons
  "," lexerRule(drop TCOMMA) cons
  ":" lexerRule(drop TCOLON) cons

  # regexes
  "\\|\\|\\|[^\r\n]*" lexerRule(readDoc TDOC) cons
  "[+\\-]?[0-9]+" lexerRule(readDecInt TINT) cons
  "[+\\-]?0[xX][0-9a-fA-F]+" lexerRule(readHexInt TINT) cons
  "[^ \t\n\r\":(),]+" lexerRule(wordToken) cons

  # newlines
  "([ \t]*(#[^\r\n]*)?[\r\n]+)+" lexerRule(drop TNEWLINE) cons

  # strings
  "\"([^\\\\\"\n\r]|\\\\[ntr\"\\\\])*\"" lexerRule(readString TSTR) cons
)

data LexerMatch
  lexerMatch(f: Str -- Token) : Maybe(Nat) -- LexerMatch
end

lexerMatchUnwrap : LexerMatch -- Maybe(Nat)
lexerMatchUnwrap = match( lexerMatch(f) -> id )

lexerMatchCmp? : LexerMatch LexerMatch -- LexerMatch LexerMatch Comp
lexerMatchCmp? = dup2 both(lexerMatchUnwrap) mcmp(ncmp)

lexerMatchOrder : Order(LexerMatch)
lexerMatchOrder = MkOrder(lexerMatchCmp?)

bestLexerMatch : Str -- LexerMatch
bestLexerMatch =
  lexerRules formap(
    match( lexerRule(f) ->
      dip(dup) strmatch lexerMatch(f)
    )
  ) nip no_panic_11(maximum(lexerMatchOrder))

data LexerError
  lexerError : Loc Str -- LexerError
end

unLexerError : LexerError -- Loc Str
unLexerError = match( lexerError -> id )

lexerError->str : LexerError -- Str
lexerError->str = unLexerError dip(loc->str ": " <>) <>

trim : Loc Str -- Loc Str
trim = dup "[ \t]+" strmatch maybe(n0, id) strbreak dip(locNext)

pretokenizeAux : List(L(Token)) Loc Str -- Result(LexerError, List(L(Token)))
pretokenizeAux =
  trim cond(
    strnull? -> drop2 Ok,
    dup bestLexerMatch match( lexerMatch(f) ->
      maybe(
        drop nip "Unrecognized token." lexerError Err,
        strbreak dip(
          dup f
          dip(locSpan locSpanEnd? dip(locSetSpan))
          swap dip(mkL cons)
        ) pretokenizeAux
      )
    )
  )

pretokenize : Mod Str -- Result(LexerError, List(L(Token)))
pretokenize = dip2(nil) dip(locStart) pretokenizeAux

"10" pretokenize
  == dip(nil) locStart "10" locSpan locSetSpan 10 TINT mkL cons Ok

"+42" pretokenize
  == dip(nil) locStart "+42" locSpan locSetSpan +42 TINT mkL cons Ok

"-5133" pretokenize
  == dip(nil) locStart "-5133" locSpan locSetSpan -5133 TINT mkL cons Ok

"0" pretokenize
  == dip(nil) locStart "0" locSpan locSetSpan 0 TINT mkL cons Ok

"0xFF" pretokenize
  == dip(nil) locStart "0xFF" locSpan locSetSpan 255 TINT mkL cons Ok

"  10" pretokenize
  == dip(nil) p1 3 zpos loc "10" locSpan locSetSpan 10 TINT mkL cons Ok

"" pretokenize == drop nil Ok
"      " pretokenize == drop nil Ok
"  \t     " pretokenize == drop nil Ok

"foobar" pretokenize
  == dip(nil) locStart "foobar" locSpan locSetSpan "foobar" TNAME mkL cons Ok

"(\n)" pretokenize
  == $(
    nil
    over p1 p1 loc "(" locSpan locSetSpan TLPAREN mkL cons
    over p1 p2 loc "\n" locSpan locSetSpan TNEWLINE mkL cons
    over p2 p1 loc ")" locSpan locSetSpan TRPAREN mkL cons
    nip Ok
  )

"||| foo bar\n|||foo" pretokenize
  == $(
    nil
    over p1 p1 loc "||| foo bar" locSpan locSetSpan "foo bar" TDOC mkL cons
    over p1 12 zpos loc "\n" locSpan locSetSpan TNEWLINE mkL cons
    over p2 p1 loc "|||foo" locSpan locSetSpan "foo" TDOC mkL cons
    nip Ok
  )

||| Convert the contents of a module into a list of located tokens.
||| This will also strip out any newline tokens inside parentheses.
||| Fails with `LexerError` if an unknown character or malformed
||| token is found.
tokenize : Mod Str -- Result(LexerError, List(L(Token)))
tokenize = pretokenize rmap(
  dip(n0)
  forfilter(
    save(
      getL cond(
        tokenIsLParen? -> drop n1+ pnat true,
        tokenIsRParen? -> drop n1- znat true,
        tokenIsNewline? -> drop n0?,
        drop true
      )
    ) swap
  )
  nip
)

"(\n)" tokenize
  == $(
    nil
    over p1 p1 loc "(" locSpan locSetSpan TLPAREN mkL cons
    over p2 p1 loc ")" locSpan locSetSpan TRPAREN mkL cons
    nip Ok
  )
